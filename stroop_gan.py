# -*- coding: utf-8 -*-
"""Stroop GAN.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1mLH8w6LFC3asfTYd0T6JkPvf8PKWkyR2
"""

d = []
t = "gameDataForTraining ({num}).txt"
for i in range(1,36):
  with open(t.format(num = i)) as f:
    for line in f:
      x = line.split(',')
      if (x[-1] == '1\n'):
        x[-1] = '1'
      elif (x[-1] == '0\n'):
        x[-1] = '0'
      d.append(x)

import pandas as pd

# Load data into a DataFrame
data = pd.DataFrame(d)

data.columns = ['Background_Color', 'Color', 'Font_Color', 'Font', 'Target']

# Check dataset
print(data.shape)
print(data.head())
print(data['Target'].value_counts())

from sklearn.preprocessing import OneHotEncoder

# Encode categorical features
encoder = OneHotEncoder()
encoded_features = encoder.fit_transform(data[['Background_Color', 'Color', 'Font_Color', 'Font']]).toarray()

# Create a new DataFrame for encoded features
import numpy as np

encoded_data = pd.DataFrame(encoded_features)
encoded_data['Target'] = data['Target']

from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report

# Split data into features (X) and target (y)
X = encoded_data.drop('Target', axis=1)
y = encoded_data['Target']

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Train a Random Forest Classifier
model = RandomForestClassifier()
model.fit(X_train, y_train)

# Evaluate the model
y_pred = model.predict(X_test)
print(classification_report(y_test, y_pred))

import torch
import torch.nn as nn
from torch.utils.data import DataLoader, TensorDataset

# Prepare data for GAN
X_train_tensor = torch.tensor(X_train.values).float()

# Define generator and discriminator
class Generator(nn.Module):
    def __init__(self, input_dim, output_dim):
        super(Generator, self).__init__()
        self.model = nn.Sequential(
            nn.Linear(input_dim, 128),
            nn.ReLU(),
            nn.Linear(128, output_dim),
            nn.Sigmoid()
        )

    def forward(self, x):
        return self.model(x)

class Discriminator(nn.Module):
    def __init__(self, input_dim):
        super(Discriminator, self).__init__()
        self.model = nn.Sequential(
            nn.Linear(input_dim, 128),
            nn.ReLU(),
            nn.Linear(128, 1),
            nn.Sigmoid()
        )

    def forward(self, x):
        return self.model(x)

# Initialize models
latent_dim = 10  # Size of the noise vector
output_dim = X_train.shape[1]
generator = Generator(latent_dim, output_dim)
discriminator = Discriminator(output_dim)

# GAN Training Loop (simplified version)
criterion = nn.BCELoss()
optimizer_g = torch.optim.Adam(generator.parameters(), lr=0.001)
optimizer_d = torch.optim.Adam(discriminator.parameters(), lr=0.001)

# Training
epochs = 1000
for epoch in range(epochs):
    # Train Discriminator
    real_data = X_train_tensor[torch.randint(0, X_train_tensor.size(0), (32,))]
    fake_data = generator(torch.randn(32, latent_dim))

    real_labels = torch.ones(32, 1)
    fake_labels = torch.zeros(32, 1)

    optimizer_d.zero_grad()
    real_loss = criterion(discriminator(real_data), real_labels)
    fake_loss = criterion(discriminator(fake_data.detach()), fake_labels)
    d_loss = real_loss + fake_loss
    d_loss.backward()
    optimizer_d.step()

    # Train Generator
    optimizer_g.zero_grad()
    g_loss = criterion(discriminator(fake_data), real_labels)  # Trick discriminator
    g_loss.backward()
    optimizer_g.step()

    if epoch % 100 == 0:
        print(f"Epoch [{epoch}/{epochs}] | D Loss: {d_loss.item():.4f} | G Loss: {g_loss.item():.4f}")

# Generate new synthetic data
noise = torch.randn(100, latent_dim)
generated_data = generator(noise).detach().numpy()
print(generated_data)

# Evaluate new data
generated_predictions = model.predict(generated_data)
print("Predictions for generated data:", generated_predictions)

# Assuming 'encoder' is the OneHotEncoder object used earlier
decoded_features = encoder.inverse_transform(generated_data)

# Convert decoded features into a DataFrame
decoded_df = pd.DataFrame(decoded_features, columns=['Background_Color', 'Foreground_Color', 'Font_Color', 'Font'])

# Add the 'Target' column (e.g., set it to 0 since we're biased toward '0')
decoded_df['Target'] = 0

print(decoded_df.head(100))

import pandas as pd

# Assuming 'decoded_df' is your decoded data frame
decoded_df.to_csv('generated_answers.txt', sep='\t', index=False)